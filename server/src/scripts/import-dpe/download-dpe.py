import requests
import pandas as pd
import time
import json
import os
from datetime import datetime

def get_api_info():
    """
    R√©cup√®re les informations sur l'API (optionnel)
    """
    info_url = "https://data.ademe.fr/data-fair/api/v1/datasets/meg-83tjwtg8dyz4vv7h1dqe"
    
    try:
        response = requests.get(info_url)
        response.raise_for_status()
        info = response.json()
        
        print("‚ÑπÔ∏è  Informations sur le dataset:")
        print(f"  - Titre: {info.get('title', 'N/A')}")
        print(f"  - Description: {info.get('description', 'N/A')[:100]}...")
        print(f"  - Nombre total de lignes: {info.get('count', 'N/A')}")
        print(f"  - Derni√®re mise √† jour: {info.get('updatedAt', 'N/A')}")
        
    except Exception as e:
        print(f"Impossible de r√©cup√©rer les infos du dataset: {e}")

def get_dpe_data():
    """
    R√©cup√®re tous les DPE de l'ADEME en utilisant le format JSON
    """
    base_url = "https://data.ademe.fr/data-fair/api/v1/datasets/meg-83tjwtg8dyz4vv7h1dqe/lines"
    
    # Param√®tres de base
    params = {
        'size': 500,
        'page': 1,
        'q_mode': 'simple',
        'finalizedAt': '2025-06-15T12:39:13.075Z',
        'format': 'json'
    }
    
    return get_dpe_data_base(base_url, params)

def get_dpe_data_with_filters(filters=None):
    """
    Version avanc√©e qui permet d'ajouter des filtres
    
    Args:
        filters (dict): Dictionnaire de filtres √† appliquer
                       Ex: {'Etiquette_DPE': 'A', 'Type_b√¢timent': 'appartement'}
    """
    base_url = "https://data.ademe.fr/data-fair/api/v1/datasets/meg-83tjwtg8dyz4vv7h1dqe/lines"
    
    params = {
        'size': 500,
        'page': 1,
        'q_mode': 'simple',
        'finalizedAt': '2025-06-15T12:39:13.075Z',
        'format': 'json'
    }
    
    # Ajouter les filtres si fournis
    if filters:
        for key, value in filters.items():
            params[f'qs'] = f'{key}:"{value}"'
    
    print(f"R√©cup√©ration avec filtres: {filters}")
    return get_dpe_data_base(base_url, params)

def get_dpe_data_base(base_url, params):
    """Fonction de base pour r√©cup√©rer les donn√©es"""
    start_time = time.time()
    page = 1
    total_records = 0
    
    # Fichiers de sortie
    output_csv = "dpe_ademe_complet.csv"
    output_jsonl = "dpe_ademe_complet.jsonl"
    
    print("D√©but de la r√©cup√©ration des donn√©es DPE...")
    print(f"üïê Heure de d√©but: {datetime.now().strftime('%H:%M:%S')}")
    print(f"üìÑ √âcriture en cours dans: {output_jsonl}")
    
    # Initialiser les fichiers
    csv_header_written = False
    
    # Ouvrir le fichier JSONL pour √©criture
    with open(output_jsonl, 'w', encoding='utf-8') as jsonl_file:
        
        while True:
            params['page'] = page
            
            try:
                # Construire l'URL compl√®te pour l'affichage
                url_with_params = f"{base_url}?" + "&".join([f"{k}={v}" for k, v in params.items()])
                print(f"üåê URL appel√©e: {url_with_params}")
                
                print(f"R√©cup√©ration de la page {page} (taille: {params['size']})...")
                
                page_start_time = time.time()
                response = requests.get(base_url, params=params)
                response.raise_for_status()
                page_duration = time.time() - page_start_time
                
                json_data = response.json()
                
                if 'results' not in json_data or not json_data['results']:
                    print(f"Page {page} vide - fin de la r√©cup√©ration")
                    break
                
                results = json_data['results']
                print(f"Page {page}: {len(results)} lignes r√©cup√©r√©es en {page_duration:.2f}s")
                
                # Convertir en DataFrame pour cette page
                df_page = pd.DataFrame(results)
                
                # √âcrire en JSONL (une ligne JSON par enregistrement)
                for record in results:
                    json.dump(record, jsonl_file, ensure_ascii=False)
                    jsonl_file.write('\n')
                
                # √âcrire en CSV (mode append apr√®s la premi√®re page)
                if not csv_header_written:
                    df_page.to_csv(output_csv, index=False, encoding='utf-8', mode='w')
                    csv_header_written = True
                else:
                    df_page.to_csv(output_csv, index=False, encoding='utf-8', mode='a', header=False)
                
                total_records += len(results)
                print(f"üìä Total √©crit: {total_records:,} enregistrements")
                
                # Si on a moins de r√©sultats que demand√©, c'est la derni√®re page
                if len(results) < params['size']:
                    print(f"Derni√®re page d√©tect√©e ({len(results)} < {params['size']})")
                    break
                
                # Pause pour √©viter de surcharger l'API
                time.sleep(0.5)
                page += 1
                
            except requests.exceptions.RequestException as e:
                print(f"Erreur lors de la requ√™te page {page}: {e}")
                break
            except KeyError as e:
                print(f"Erreur de format JSON page {page}: {e}")
                print("R√©ponse re√ßue:", response.text[:500])
                break
            except Exception as e:
                print(f"Erreur inattendue page {page}: {e}")
                break
    
    total_time = time.time() - start_time
    
    if total_records > 0:
        print(f"\n‚úÖ R√©cup√©ration termin√©e!")
        print(f"‚è±Ô∏è  Temps total d'ex√©cution: {total_time:.2f}s ({total_time/60:.1f} min)")
        print(f"üìä Total de lignes r√©cup√©r√©es: {total_records:,}")
        print(f"‚ö° Vitesse moyenne: {total_records/total_time:.1f} lignes/seconde")
        print(f"üìÑ Donn√©es sauvegard√©es dans:")
        
        if os.path.exists(output_csv):
            print(f"   - CSV: {output_csv} ({os.path.getsize(output_csv) / (1024*1024):.2f} MB)")
        if os.path.exists(output_jsonl):
            print(f"   - JSONL: {output_jsonl} ({os.path.getsize(output_jsonl) / (1024*1024):.2f} MB)")
        
        print(f"üïê Heure de fin: {datetime.now().strftime('%H:%M:%S')}")
        
        # Retourner un DataFrame avec un √©chantillon pour compatibilit√©
        print(f"\nüìñ Lecture d'un √©chantillon pour aper√ßu...")
        sample_df = pd.read_json(output_jsonl, lines=True, nrows=1000)
        
        # Afficher quelques statistiques
        print(f"\nüìà Aper√ßu des colonnes disponibles:")
        for col in sample_df.columns[:10]:  # Afficher les 10 premi√®res colonnes
            print(f"  - {col}")
        if len(sample_df.columns) > 10:
            print(f"  ... et {len(sample_df.columns) - 10} autres colonnes")
        
        return sample_df
    else:
        print("‚ùå Aucune donn√©e r√©cup√©r√©e")
        print(f"‚è±Ô∏è  Temps total d'ex√©cution: {total_time:.2f}s")
        return None

if __name__ == "__main__":
    # R√©cup√©rer les infos du dataset
    get_api_info()
    print("\n" + "="*50 + "\n")
    
    # R√©cup√©ration des donn√©es
    print("üîÑ R√©cup√©ration des donn√©es DPE...")
    df = get_dpe_data()
    
    if df is not None:
        print(f"\nüîç Aper√ßu des premi√®res lignes:")
        print(df.head())
        
        print(f"\nüìã Colonnes disponibles ({len(df.columns)}):")
        for i, col in enumerate(df.columns):
            print(f"  {i+1:2d}. {col}")
    
    # Exemple avec filtres
    print(f"\n{'='*50}")
    print("üí° Pour utiliser des filtres, vous pouvez utiliser:")
    print("df_A = get_dpe_data_with_filters({'Etiquette_DPE': 'A'})")
    print("df_B = get_dpe_data_with_filters({'Etiquette_DPE': 'B'})")
    print("df_all = pd.concat([df_A, df_B, ...])")